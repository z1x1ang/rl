<!DOCTYPE html>
<html>
<head>
    <title>马尔可夫链到最优策略</title>
    <script src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
    <style>
        #bellmanmaxDes{
            width: 310px;
            word-wrap: break-word;
        }
    </style>
</head>
<body>
      <!-- 小标题的容器 -->
      <div id="subtitle">
        <p>求职马尔可夫链</p>
    </div>
    <div style="display: inline-block; vertical-align: top;">
        <!-- 图的容器 -->
        <div id="mynetwork" style="width: 800px; height: 600px;"></div>
    </div>
    <div style="display: inline-block; vertical-align: top;">
        <!-- 按钮和矩阵的容器 -->
        <div>
            <button id="showMatrix">1显示该图状态转移矩阵<span style="font-weight: bold;">P</span></button>
            <div id="matrixContainer" style="margin-top:20px;"></div>
        </div>
        <div>
            <button id="showMatrixP">2变成求职马尔可夫决策过程</button>
            <button id="showOriginal">求职马尔可夫链</button>
            <div id="matrixIntro" style="margin-top:20px;"></div>
        </div>
        <div>
            <button id="matrixpi">3马尔可夫决策过程策略</button>
            <div id="matrixPpi" style="margin-top:20px;"></div>
        </div>
        <div>
            <button id="bellman">4验证贝尔曼方程</button>
            <div id="bellmanDes" style="margin-top:20px;"></div>
        </div>
        <div>
            <button id="bellmanmax">5验证贝尔曼最优方程</button>
            <div id="bellmanmaxDes" style="margin-top:20px;"></div>
        </div>
        <div>
            <button id="bellmanmaxp">6最优策略</button>
            <div id="bellmanmaxDesp" style="margin-top:20px;"></div>
        </div>
    </div>
    <script>
        var nodes = new vis.DataSet([
            { id: 1, label: '本职工作',x: -200, y: -200, fixed: true },
            { id: 2, label: '人工智能工作' ,shape:'box',x:200, y: -200, fixed: true},
            { id: 3, label: '机器学习' ,x: -150, y: -50, fixed: true},
            { id: 4, label: '强化学习' ,x: 40, y: -50, fixed: true},
            { id: 5, label: '深度强化' ,x: 251, y: -50, fixed: true},
            { id: 6, label: '故宫旅游' ,x: 10, y: 100, fixed: true}
        ]);
        var edges = new vis.DataSet([
            { from: 6, to: 5, arrows: 'to', label: '0.6' },
            { from: 4, to: 5, arrows: 'to', label: '1/3' },
            { from: 5, to: 6, arrows: 'to', label: '0.5' },
            { from: 6, to: 4, arrows: 'to', label: '0.2' },
            { from: 1, to: 1, arrows: 'to', label: '0.5' }, 
            { from: 1, to: 3, arrows: 'to', label: '0.5' },
            { from: 3, to: 2, arrows: 'to', label: '1/3' },
            { from: 3, to: 1, arrows: 'to', label: '1/3' },
            { from: 4, to: 2, arrows: 'to', label: '1/3' },
            { from: 5, to: 2, arrows: 'to', label: '0.5' },
            { from: 6, to: 3, arrows: 'to', label: '0.2' },
            { from: 3, to: 4, arrows: 'to', label: '1/3' },
            { from: 4, to: 1, arrows: 'to', label: '1/3' },
        ]);
      // 存储初始状态
      // 存储节点和边的初始状态
var initialNodesState = nodes.get({
    returnType: 'Object'
});
      var initialEdgesState = edges.get({
    returnType: 'Object'
});
        var container = document.getElementById('mynetwork');
        var data = {
            nodes: nodes,
            edges: edges
        };
        var options = {
            edges: {
                font: {
                    align: 'top'
                }
            }   
        };
        var network = new vis.Network(container, data, options);
// 假设您的状态转移矩阵是固定大小的，并初始化为全0
var matrixSize = 6; // 假设我们有6个状态
var transitionMatrix = Array.from({ length: matrixSize }, () => new Array(matrixSize).fill(0));
// 现在我们填充状态转移矩阵
// 现在我们填充状态转移矩阵
edges.forEach((edge) => {
    // 将label转换为数值，对于"1/3"这样的分数，保持其字符串形式
    var probability = edge.label;
    // 如果label是分数字符串，直接使用，否则尝试将其转换为数值
    if (probability.includes('/')) {
        transitionMatrix[edge.from - 1][edge.to - 1] = probability;
    } else {
        transitionMatrix[edge.from - 1][edge.to - 1] = parseFloat(probability);
    }
});
//将第二行最后一个元素设置为1,因为人工智能工作转移到下一个状态人工智能工作的概率是100%(已终止)
transitionMatrix[1][matrixSize-1]=1
function showMatrix() {
    // 创建一个 LaTeX 矩阵字符串
    var latexMatrix = '\\begin{bmatrix}';
    // 添加矩阵的行
    for (var i = 0; i < transitionMatrix.length; i++) {
        // 添加矩阵的列
        for (var j = 0; j < transitionMatrix[i].length; j++) {
            // 添加 LaTeX 矩阵中的元素
            latexMatrix += transitionMatrix[i][j];
            // 如果不是最后一个元素，添加 & 来分隔
            if (j < transitionMatrix[i].length - 1) {
                latexMatrix += ' & ';
            }
        }
        // 如果不是最后一行，添加 \\ 来换行
        if (i < transitionMatrix.length - 1) {
            latexMatrix += ' \\\\ ';
        }
    }
    latexMatrix += '\\end{bmatrix}';
    // 找到页面上用于显示矩阵的元素
    const matrixContainer = document.getElementById('matrixContainer');
    // 使用 MathJax 定界符包围我们的 LaTeX 矩阵
    var mathjaxMatrix = '$$' + latexMatrix + '$$';
    // 设置元素的文本内容为我们创建的 LaTeX 矩阵字符串
    matrixContainer.innerHTML = mathjaxMatrix; // 使用 innerHTML 而不是 textContent
    // 通知 MathJax 渲染更新的数学表达式
    MathJax.typesetPromise().then(() => {
        const descriptionText = '矩阵从上至下,从左至右分别为本...人...机...强...深...故...<br>由于人工智能工作是终止态,<br>所以它转移到人工智能工作的概率为100%.<br>矩阵每行相加都等于1';
        const pElement = document.createElement('p');
        pElement.innerHTML = descriptionText;
        matrixContainer.appendChild(pElement); // 使用 appendChild 方法插入元素
    }).catch((err) => {
        console.error('MathJax rendering error:', err);
    });

}
// 创建一个函数来恢复初始状态
function resetGraph() {
     // 重置所有节点到它们的初始状态
     nodes.update(Object.values(initialNodesState));
    // 如果你有边的初始状态也需要重置，同样的方法：
    edges.update(Object.values(initialEdgesState));
    nodes.update({ id: 6, color: null });
    document.querySelector('#subtitle p').textContent='求职马尔可夫链'
    document.getElementById('matrixIntro').innerHTML=""
}

// 给变成求职马尔可夫决策过程的按钮添加事件监听器
document.getElementById('showMatrixP').addEventListener('click', function() {
    const mdpIntro=document.getElementById('matrixIntro');
    mdpIntro.innerHTML="马尔可夫过程->马尔可夫决策过程中，<br>\
    其中有一个节点变成了黑点(故宫旅游)，此图去掉了故宫旅游状态，<br>\
    表示选择旅游动作时，主动进入了一个临时状态随后被动地被<br>\
    环境按照其动力学分配到另外三个状态，<br>\
    也就是说此时求职者没有选择权决定去哪一个状态。<br>\
    状态集合S={本职工作、机器学习、强化学习、深度强化、<br>人工智能工作}<br>\
动作集合A={继续本职工作、学习、放弃、找工作、旅游}<br>\
\\(P^a_{ss'}\\)(状态s在a行为的影响下，转移到状态s'的概率)<br>\
当求职者位于'本职工作'状态，采取行为'学习'，<br>转移到'机器学习'的概率为1，<br>\
转移到其他状态的概率为0。位于'深度强化'状态时，<br>\
采取行为`旅游`时,转移到`机器学习`和`强化学习`的概率均为0.2，<br>\
转移到深度强化的概率为0.6。回报和状态行为对挂钩\\(r^a_s\\)"
MathJax.typesetPromise([mdpIntro]);
    // 将故宫旅游节点变为黑点
    nodes.update({id: 6, label: '故宫旅游', color: { background: 'black'}});
    nodes.update({id:2,shape:null});
    document.querySelector('#subtitle p').textContent="求职马尔可夫决策过程"
    // 获取所有的边
    var updatedEdges = [];
edges.forEach((edge) => {
    let label = '';
    if (edge.from !== 6) {
        if(edge.from==1 && edge.to==1) label = '继续本职工作R=2';
        else if(edge.from==1 && edge.to==3) label = '学习R=10';
        else if(edge.from==3 && edge.to==1) label = '放弃R=-10';
        else if(edge.from==4 && edge.to==1) label = '放弃R=-10';
        else if(edge.from==4 && edge.to==5) label = '学习R=-2';
        else if(edge.from==5 && edge.to==6) label = '旅游R=1';
        else if(edge.from==4 && edge.to==2) label = '找工作R=8';
        else if(edge.from==5 && edge.to==2) label = '找工作R=10';
        // 只有当标签实际上改变了，我们才更新边
        if (label && label !== edge.label) {
            updatedEdges.push({id: edge.id, label: label});
        }
    }
});
// 批量更新边
edges.update(updatedEdges);
});
// 添加按钮的事件监听器
document.getElementById('showOriginal').addEventListener('click', function() {
    resetGraph(); // 当按钮被点击时，恢复图形
});
// 给按钮添加事件监听器
document.getElementById('showMatrix').addEventListener('click', showMatrix);
document.getElementById("matrixpi").addEventListener('click',function(){
    resetGraph()
    nodes.update({id: 6, label: '故宫旅游', color: { background: 'black'}});
    nodes.update({id:2,shape:null});
    document.getElementById('matrixIntro').innerHTML=""
    document.querySelector('#subtitle p').textContent='马尔可夫决策过程策略';
    const mdppi=document.getElementById('matrixPpi')
    mdppi.innerHTML="当前策略\\(\\pi\\)下，状态`深度强化`到状态`强化学习`的转移概率为\
\\[P^{\\pi}_{ss'}=\\sum_{a\\in A}{\\pi}(a|s)P^a_{ss'}=0.5*0.2+0.5*0=0.1\\]\
当前策略\\(\\pi\\)下，状态`深度强化`对应的回报为\
\\[R^{\\pi}_s=\\sum_{a\\in A}{\\pi}(a|s)R^a_s=0.5*1+0.5*10=5.5\\]"
MathJax.typesetPromise([mdppi]);
});
document.getElementById('bellman').addEventListener('click',function(){
    document.getElementById('showMatrixP').click();
    const bellmanDes=document.getElementById('bellmanDes');
    bellmanDes.innerHTML=`<a href="https://flowus.cn/share/f99b7256-2e41-4000-8d96-23ee2ca30806">贝尔曼方程推导过程<br></a>`
    document.getElementById('matrixIntro').innerHTML=""
    //const fuhao=MathJax.typesetPromise([mdppi]);
    nodes.update({id: 1, label: '本职工作V₁=14.28125',font:{size:8}});
    nodes.update({id: 2, label: '人工智能工作V₂=0',font:{size:8}});
    nodes.update({id: 3, label: '机器学习V₃=4.28125',font:{size:8}});
    nodes.update({id: 4, label: '强化学习V₄=6.5625',font:{size:8}});
    nodes.update({id: 5, label: '深度强化学习V₅=9.40625',font:{size:8}});
       // 更新边标签
       let updates=[]
       let label = '';
       edges.forEach((edge)=>{
        if (edge.from !== 6) {
        if(edge.from==1 && edge.to==1) label = '继续本职工作R=0Q₁₁=14.28125';
        else if(edge.from==1 && edge.to==3) label = '学习R=10Q₁₂=14.28125';
        else if(edge.from==3 && edge.to==1) label = '放弃R=-10Q₃₁=4.28125';
        else if(edge.from==4 && edge.to==1) label = '放弃R=-10Q₄₁=4.28125';
        else if(edge.from==4 && edge.to==5) label = '学习R=-2Q₄₃=7.40625';
        else if(edge.from==5 && edge.to==6) label = '旅游R=1Q₅₂=8.8125';
        else if(edge.from==4 && edge.to==2) label = '找工作R=8Q₄₂=8';
        else if(edge.from==5 && edge.to==2) label = '找工作R=10Q₅₁=10';
        else if(edge.from==3 && edge.to==2) label = '找工作R=4Q₃₂=4';
        else if(edge.from==3 && edge.to==4) label = '学习R=-2Q₃₃=4.5625';
        if (label && label !== edge.label) {
        updates.push({id:edge.id,label:label,font:{size:10}})
        }
        }
       })
       edges.update(updates);
       bellmanDes.innerHTML+="\\(V_{\\pi}(s)=\\sum_{a\\in A}{\\pi(a|s)(R^a_s+\\gamma \\sum_{s'\\in S}P_{ss'}^aV_{\\pi}(s'))}\\)<br>\
假设选择状态'强化学习'为研究对象，则此状态对应值函数\\(V_4\\) \<br>表示当前状态值函数\\(V_{\\pi}(s)\\), \\(V_4\\)的下继状态值函数<br>\\(V_1,V_2,V_5\\)表示下一步状态值函数\\(V_{\\pi}(s')\\)<br>\
已知\\(V_4,V_2,V_1,V_5\\)的值,状态转换概率均为1/3<br>\
\\begin{align}\
V_4 &= \\frac{1}{3}*[(-10 + 1 * 1 * V_1) + (8 + 1 * 1 * V_2) \\\\\
    &+ (-2 + 1 * 1 * V_5)] \\\\\
    &= 6.5625 \\\\\
\\end{align}\
其余验证及详细内容见上方链接"
MathJax.typesetPromise([bellmanDes]);
})
document.getElementById('bellmanmax').addEventListener('click',function(){
    document.getElementById('showMatrixP').click();
    document.querySelector('#subtitle p').textContent='最优值函数'
    document.getElementById('matrixIntro').innerHTML=""
    nodes.update({id: 1, label: '本职工作V₁*=16'});
    nodes.update({id: 2, label: '人工智能工作V₂*=0'});
    nodes.update({id: 3, label: '机器学习V₃*=6'});
    nodes.update({id: 4, label: '强化学习V₄*=8'});
    nodes.update({id: 5, label: '深度强化学习V₅*=10'});
//更新边标签
let updates=[]
let label=''
edges.forEach((edge)=>{
    if(edge.from!==6){
        if(edge.from==1 && edge.to==1) label = '继续本职工作R=0Q₁₁*=16';
        else if(edge.from==1 && edge.to==3) label = '学习R=10Q₁₂*=16';
        else if(edge.from==3 && edge.to==1) label = '放弃R=-10Q₃₁*=6';
        else if(edge.from==4 && edge.to==5) label = '学习R=-2Q₄₃*=8';
        else if(edge.from==4 && edge.to==2) label = '找工作R=8Q₄₂*=8';
        else if(edge.from==5 && edge.to==2) label = '找工作R=10Q₅₁*=10';
        else if(edge.from==3 && edge.to==4) label = '学习R=-2Q₃₃*=6';
        if (label && label !== edge.label) {
        updates.push({id:edge.id,label:label,font:{size:10}})
        }
    }
})
edges.forEach((edge)=>{
    if(edge.from==3 && edge.to==2) edges.remove(edge.id)
    if(edge.from==4 && edge.to==1) edges.remove(edge.id)
    if(edge.from==5 && edge.to==6) edges.remove(edge.id)

})

edges.update(updates);

bellmanmaxDes.innerHTML=`<a href="https://flowus.cn/share/b722609e-8bfa-4d7f-9844-978c97573197">贝尔曼最优方程推导过程<br></a>`
bellmanmaxDes.innerHTML+="假设已经求得最优值函数和最优行为值函数<br>\
验证\\(V^*(s)\\)和\\(V^*(s')\\)关系公式<br>\
\\(V^*(s)=\\max_aR_s^a+\\gamma \\sum_{s' \\in S}P^a_{ss'}V^*(s')\\)<br>\
以'本职工作'作为研究状态<br>\
\\(V_1^*=max(0+V_1^*,10+V_3^*=max(0+16,10+6)=16\\)<br>\
验证\\(Q^*(s,a)和Q^*(s',a')\\)关系公式<br>\
\\(Q^*(s,a)=R^a_s+\\gamma \\sum_{s'\\in S}P^a_{ss'}\\max_{a'}Q^*(s',a')\\)<br>\
继续选择'本职工作'为研究对象<br>\
\\begin{align}\
Q_{11}^*&=0+1*1*\\max(Q_{11}^*,Q_{12}^*)=0+1*1*\\max(16,16)\\\\\
        &=16\\\\\
\\end{align}\
其余验证及详细内容见上方链接"
MathJax.typesetPromise([bellmanmaxDes]);
})
document.getElementById('bellmanmaxp').addEventListener('click',function(){
    document.getElementById('bellmanmax').click()
    bellmanmaxDes.innerHTML=''
    document.querySelector('#subtitle p').textContent='最优策略'
    const maxpi=document.getElementById('bellmanmaxDesp');
    maxpi.innerHTML="\\({\\pi}^*(a|s)=\argmax_{a \\in A}\\left(R^a_s+\\gamma \\sum_{s' \\in S}P^a_{ss'}V^*(s')\\right)\\)<br>\
\\({\\pi}^*(a|s) = \\\\\
\\begin{cases} \\\\\
1 & a=\argmax_{a \\in A}Q^*(s,a) \\\\\
0 & 其他 \\\\\
\\end{cases}\\\\\
\\)<br>\
若在当前状态s下,有m个行为值函数相等且取值最大,则其对<br>应的行为概率均为\\(\frac{1}{m}\\)\
如'机器学习'状态下<br>\\(Q^*_{31}=Q^*_{33}>Q^*_{32}\\)，则'放弃'和'学习'的概率均为\\(\\frac{1}{2}\\)"
MathJax.typesetPromise([maxpi])
})
</script>
</body>
</html>
